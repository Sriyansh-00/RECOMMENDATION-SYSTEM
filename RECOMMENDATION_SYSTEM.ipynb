{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrSML/27ErM4efVN8MPb6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sriyansh-00/RECOMMENDATION-SYSTEM/blob/main/RECOMMENDATION_SYSTEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsqj4KqxfGWp",
        "outputId": "bd2a573b-e660-433b-9668-a264b619b3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-19 09:56:45--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip.2’\n",
            "\n",
            "ml-100k.zip.2       100%[===================>]   4.70M  8.50MB/s    in 0.6s    \n",
            "\n",
            "2025-06-19 09:56:46 (8.50 MB/s) - ‘ml-100k.zip.2’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ],
      "source": [
        "# SETUP AND DATASET DOWNLOAD (No Kaggle needed)\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  DATA LOADING AND PREPROCESSING (FIXED DUPLICATES ISSUE)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the data from the extracted files\n",
        "ratings_path = 'ml-100k/u.data'\n",
        "movies_path = 'ml-100k/u.item'\n",
        "\n",
        "# Load ratings data\n",
        "ratings_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "ratings_df = pd.read_csv(ratings_path, sep='\\t', names=ratings_cols, encoding='latin-1')\n",
        "\n",
        "# Load movie information\n",
        "movies_cols = [\n",
        "    'movie_id', 'movie_title', 'release_date', 'video_release_date',\n",
        "    'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "    'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        "    'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
        "    'Thriller', 'War', 'Western'\n",
        "]\n",
        "movies_df = pd.read_csv(movies_path, sep='|', names=movies_cols, encoding='latin-1')\n",
        "\n",
        "# Merge movie titles with ratings\n",
        "ratings_df = ratings_df.merge(movies_df[['movie_id', 'movie_title']], left_on='item_id', right_on='movie_id')\n",
        "ratings_df.drop(columns=['movie_id', 'timestamp'], inplace=True)\n",
        "\n",
        "# Handle duplicates by taking the mean rating for user-movie pairs\n",
        "ratings_df = ratings_df.groupby(['user_id', 'movie_title'])['rating'].mean().reset_index()\n",
        "\n",
        "# Create user-item matrix\n",
        "user_item_matrix = ratings_df.pivot(index='user_id', columns='movie_title', values='rating').fillna(0)\n",
        "\n",
        "# Split data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data exploration\n",
        "print(\"MovieLens 100K Dataset Overview:\")\n",
        "print(f\"Total ratings: {len(ratings_df)}\")\n",
        "print(f\"Unique users: {ratings_df['user_id'].nunique()}\")\n",
        "print(f\"Unique movies: {ratings_df['movie_title'].nunique()}\")\n",
        "print(\"\\nSample ratings:\")\n",
        "print(ratings_df.head())\n",
        "print(\"\\nSample movies:\")\n",
        "print(movies_df[['movie_id', 'movie_title']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAxuP9lyg96R",
        "outputId": "5ae55ca2-2f68-4f16-cc19-847ca161fd5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MovieLens 100K Dataset Overview:\n",
            "Total ratings: 99693\n",
            "Unique users: 943\n",
            "Unique movies: 1664\n",
            "\n",
            "Sample ratings:\n",
            "   user_id                          movie_title  rating\n",
            "0        1                101 Dalmatians (1996)     2.0\n",
            "1        1                  12 Angry Men (1957)     5.0\n",
            "2        1  20,000 Leagues Under the Sea (1954)     3.0\n",
            "3        1         2001: A Space Odyssey (1968)     4.0\n",
            "4        1                    Abyss, The (1989)     3.0\n",
            "\n",
            "Sample movies:\n",
            "   movie_id        movie_title\n",
            "0         1   Toy Story (1995)\n",
            "1         2   GoldenEye (1995)\n",
            "2         3  Four Rooms (1995)\n",
            "3         4  Get Shorty (1995)\n",
            "4         5     Copycat (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  USER-USER COLLABORATIVE FILTERING\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def user_user_cf(user_item_matrix, target_user, k=5):\n",
        "    \"\"\"User-based collaborative filtering\"\"\"\n",
        "    user_similarity = cosine_similarity(user_item_matrix)\n",
        "    np.fill_diagonal(user_similarity, 0)\n",
        "\n",
        "    user_idx = user_item_matrix.index.get_loc(target_user)\n",
        "    similar_users = np.argsort(user_similarity[user_idx])[-k:]\n",
        "\n",
        "    predictions = []\n",
        "    target_ratings = user_item_matrix.iloc[user_idx]\n",
        "    unrated_movies = target_ratings[target_ratings == 0].index\n",
        "\n",
        "    for movie in unrated_movies:\n",
        "        movie_idx = user_item_matrix.columns.get_loc(movie)\n",
        "        numerator = user_similarity[user_idx, similar_users] @ user_item_matrix.iloc[similar_users, movie_idx]\n",
        "        denominator = np.sum(np.abs(user_similarity[user_idx, similar_users]))\n",
        "        if denominator > 0:\n",
        "            pred_rating = numerator / denominator\n",
        "            predictions.append((movie, pred_rating))\n",
        "\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    return predictions[:10]\n",
        "\n",
        "# Example usage\n",
        "sample_user = 196\n",
        "print(f\"\\nTop 10 Recommendations for User {sample_user}:\")\n",
        "for movie, rating in user_user_cf(user_item_matrix, sample_user):\n",
        "    print(f\"{movie}: {rating:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BoIn93Rin3C",
        "outputId": "0b821b5b-1d11-4a58-f33a-2efb71710c01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Recommendations for User 196:\n",
            "Back to the Future (1985): 3.33\n",
            "Fargo (1996): 3.28\n",
            "Monty Python and the Holy Grail (1974): 3.15\n",
            "Indiana Jones and the Last Crusade (1989): 3.12\n",
            "Butch Cassidy and the Sundance Kid (1969): 2.91\n",
            "Sting, The (1973): 2.91\n",
            "When Harry Met Sally... (1989): 2.83\n",
            "Dave (1993): 2.80\n",
            "Pulp Fiction (1994): 2.78\n",
            "Star Wars (1977): 2.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  ITEM-ITEM COLLABORATIVE FILTERING\n",
        "def item_item_cf(user_item_matrix, target_user, k=5):\n",
        "    \"\"\"Item-based collaborative filtering\"\"\"\n",
        "    item_similarity = cosine_similarity(user_item_matrix.T)\n",
        "    np.fill_diagonal(item_similarity, 0)\n",
        "\n",
        "    user_idx = user_item_matrix.index.get_loc(target_user)\n",
        "    rated_movies = user_item_matrix.iloc[user_idx][user_item_matrix.iloc[user_idx] > 0]\n",
        "\n",
        "    predictions = []\n",
        "    for movie in user_item_matrix.columns:\n",
        "        if not rated_movies.get(movie, False):\n",
        "            movie_idx = user_item_matrix.columns.get_loc(movie)\n",
        "            similar_movies = np.argsort(item_similarity[movie_idx])[-k:]\n",
        "\n",
        "            similar_movies_rated = [\n",
        "                (sim_movie, item_similarity[movie_idx, sim_movie], user_item_matrix.iloc[user_idx, sim_movie])\n",
        "                for sim_movie in similar_movies\n",
        "                if user_item_matrix.iloc[user_idx, sim_movie] > 0\n",
        "            ]\n",
        "\n",
        "            if similar_movies_rated:\n",
        "                sim_scores = np.array([sim[1] for sim in similar_movies_rated])\n",
        "                ratings = np.array([sim[2] for sim in similar_movies_rated])\n",
        "                pred_rating = np.dot(sim_scores, ratings) / np.sum(sim_scores)\n",
        "                predictions.append((movie, pred_rating))\n",
        "\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    return predictions[:10]\n",
        "\n",
        "# Example usage\n",
        "print(f\"\\nTop 10 Recommendations for User {sample_user}:\")\n",
        "for movie, rating in item_item_cf(user_item_matrix, sample_user):\n",
        "    print(f\"{movie}: {rating:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lADIrg0Cipyi",
        "outputId": "3db9b824-c8b0-4e01-f05c-93741fce1ade"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Recommendations for User 196:\n",
            "Billy Madison (1995): 5.00\n",
            "Local Hero (1983): 5.00\n",
            "Man Who Would Be King, The (1975): 5.00\n",
            "Young Guns II (1990): 5.00\n",
            "Ace Ventura: When Nature Calls (1995): 5.00\n",
            "Airheads (1994): 5.00\n",
            "Another Stakeout (1993): 5.00\n",
            "Benny & Joon (1993): 5.00\n",
            "Beverly Hills Cop III (1994): 5.00\n",
            "Boomerang (1992): 5.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX FACTORIZATION (SVD) - FIXED SYNTAX\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def matrix_factorization(train_df, user_item_matrix, k=10):\n",
        "    \"\"\"Matrix factorization with SVD\"\"\"\n",
        "    # Convert to numpy array and subtract user means\n",
        "    R = user_item_matrix.values\n",
        "    user_ratings_mean = np.mean(R, axis=1)\n",
        "    R_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
        "\n",
        "    # Perform SVD\n",
        "    U, sigma, Vt = svds(R_demeaned, k=k)\n",
        "    sigma = np.diag(sigma)\n",
        "\n",
        "    # Make predictions\n",
        "    all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)\n",
        "    preds_df = pd.DataFrame(all_user_predicted_ratings, columns=user_item_matrix.columns, index=user_item_matrix.index)\n",
        "\n",
        "    return preds_df\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining Matrix Factorization...\")\n",
        "preds_df = matrix_factorization(train_df, user_item_matrix, k=10)\n",
        "\n",
        "# Get recommendations for sample user - FIXED SYNTAX\n",
        "def recommend_mf(user_id, preds_df, user_item_matrix, n=10):\n",
        "    # Get and sort the user's predictions\n",
        "    user_row = user_item_matrix.index.get_loc(user_id)\n",
        "    sorted_user_predictions = preds_df.iloc[user_row].sort_values(ascending=False)\n",
        "\n",
        "    # Get the user's data and merge in the movie information\n",
        "    user_data = user_item_matrix.iloc[user_row]\n",
        "    user_full = (user_data.to_frame()\n",
        "                .reset_index()\n",
        "                .rename(columns={user_data.name: 'actual'}))\n",
        "\n",
        "    # Recommend the highest predicted rating movies not yet rated\n",
        "    recommendations = (sorted_user_predictions.to_frame()\n",
        "                      .reset_index()\n",
        "                      .rename(columns={sorted_user_predictions.name: 'predicted'}))\n",
        "\n",
        "    # Merge with user_full to filter out already rated movies\n",
        "    recs = recommendations[~recommendations['movie_title'].isin(user_full['movie_title'])]\n",
        "    recs = recs.sort_values('predicted', ascending=False).head(n)\n",
        "\n",
        "    return recs\n",
        "\n",
        "# Example usage\n",
        "sample_user = 196\n",
        "print(f\"\\nTop 10 MF Recommendations for User {sample_user}:\")\n",
        "recommendations = recommend_mf(sample_user, preds_df, user_item_matrix)\n",
        "print(recommendations[['movie_title', 'predicted']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWHAq7jfir8q",
        "outputId": "9bb21f88-fa3c-4d14-e1be-0c7ffedba24b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Matrix Factorization...\n",
            "\n",
            "Top 10 MF Recommendations for User 196:\n",
            "Empty DataFrame\n",
            "Columns: [movie_title, predicted]\n",
            "Index: []\n"
          ]
        }
      ]
    }
  ]
}